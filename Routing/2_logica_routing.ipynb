{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b47314e-b7e0-4dd3-869c-f095ac126507",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LangSmithParams' from 'langchain_core.language_models.chat_models' (D:\\Anaconda\\envs\\llm\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_v1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m my_gpt\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Data model\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\llm\\lib\\site-packages\\langchain_openai\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Module for OpenAI integrations.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI, ChatOpenAI\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAIEmbeddings, OpenAIEmbeddings\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAI, OpenAI\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\llm\\lib\\site-packages\\langchain_openai\\chat_models\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Module for OpenAI chat models.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAzureChatOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\llm\\lib\\site-packages\\langchain_openai\\chat_models\\azure.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LanguageModelInput\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LangSmithParams\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGenerationChunk, ChatResult\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Runnable\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'LangSmithParams' from 'langchain_core.language_models.chat_models' (D:\\Anaconda\\envs\\llm\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py)"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from sk import my_gpt\n",
    "\n",
    "# Data model\n",
    "class RouterQuery(BaseModel):\n",
    "    \"\"\" Router a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    datasource: Literal[\"python_doc\", \"js_doc\", \"java_doc\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question, choose which datasource would be most relevant for answering their question\"    \n",
    "    )\n",
    "\n",
    "# LLM with functional call\n",
    "model = ChatOpenAI(api_key = my_gpt, model = \"gpt-4o\")\n",
    "strtuctured_model = model.with_structured_output(RouterQuery)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are an expert at routing a user question to the appropriate data source.\n",
    "Based on the programming language the question is referring to, route it to the relevant data source.\"\"\"\n",
    "\n",
    "prompt  = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "router = prompt | strtuctured_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aa5d4df-2534-4dfb-a8df-a7751145e4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouterQuery(datasource='python_doc')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"\"\" Why doesn't the following code work\":\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt  = ChatPromptTemplate.from_messages([\"human\", \"speak in {language}\"])\n",
    "promt.invoke(\"Uzbek\")\n",
    "\"\"\"\n",
    "res = router.invoke({\"question\": question})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "832ce417-e4ed-44d0-a0e1-e1dc4987a16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'java_doc'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "question = \"\"\" Why doesn't the following code work\":\n",
    "public class HelloWorld {\n",
    "    public static void main(String[] args) {\n",
    "        System.out.println(\"Hello, World!\");\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "res = router.invoke({\"question\": question})\n",
    "res.datasource\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e459cdd-6b8c-4fa1-81c2-0a149c2bffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_route(result):\n",
    "    if \"python_doc\" in res.datasource.lower():\n",
    "        # Logic here\n",
    "        return \"chain for python_doc.\"\n",
    "    elif \"java_doc\" in res.datasource.lower():   \n",
    "        # Logic here\n",
    "        return \"chain for java_do.c\"\n",
    "    else:\n",
    "        # Logic here\n",
    "        return \"chain for js_doc.\"\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "full_chain = router | RunnableLambda(choose_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3af702f0-753b-4afa-8459-c8ee011d01c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chain for java_doc'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = full_chain.invoke({\"question\": question})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7699f95a-be77-4a9e-ab2b-00c27d2c3078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faiss_index_cv_resume\n",
      "CV.pdf\n",
      "faiss_index_company_info\n",
      "DMS.pdf\n",
      "faiss_index_llm_interview\n",
      "LLM_Interview.pdf\n"
     ]
    }
   ],
   "source": [
    "document_mapping = {\n",
    "        \"cv_resume\": \"CV.pdf\",  # Replace with your actual CV filename\n",
    "        \"company_info\": \"DMS.pdf\",  # Replace with your company doc filename\n",
    "        \"llm_interview\": \"LLM_Interview.pdf\"  # Replace with your interview questions filename\n",
    "    }\n",
    "for doc_type, filename in document_mapping.items():\n",
    "    vector_path = f\"faiss_index_{doc_type}\"\n",
    "    print(vector_path)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c74bec-2a61-49d2-a59d-12eab8a20090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
