{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab46da2-48c0-4c6d-b614-4360ffc0f065",
   "metadata": {},
   "source": [
    "### AGENTIC ROUTING\n",
    "\n",
    "Unlike logical routing (pick ONE route), agentic routing:\n",
    "- Agent dynamically decides which tools to use\n",
    "- Can use multiple sources in a single query\n",
    "- Most flexible, but usually slowest / most expensive\n",
    "\n",
    "Key difference:\n",
    "- Patterns 1–3: Static → pick ONE → execute\n",
    "- Agentic: Dynamic → agent decides → may use MULTIPLE\n",
    "\n",
    "Diagram:\n",
    "    Query → Agent → [Tool 1] → [Tool 2] → ... → Synthesize → Response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864bef56-87ed-4859-a10a-19ffe69bd744",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AgentExecutor' from 'langchain.agents' (D:\\Anaconda\\envs\\rag\\Lib\\site-packages\\langchain\\agents\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_text_splitters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AgentExecutor, create_openai_tools_agent\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tool\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'AgentExecutor' from 'langchain.agents' (D:\\Anaconda\\envs\\rag\\Lib\\site-packages\\langchain\\agents\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import MessagesPlaceholder, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "import os\n",
    "from sk import my_gpt\n",
    "from config import (\n",
    "    llm, embeddings, setup_vectorstores,\n",
    "    get_retriever, format_docs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c4d676-6dbc-40a5-b8a3-e115f76000d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(vectorstores):\n",
    "    \"\"\"Create agent with multiple tools.\"\"\"\n",
    "    \n",
    "    @tool\n",
    "    def calculator(expression: str) -> str:\n",
    "        \"\"\"Calculate mathematical expressions.\"\"\"\n",
    "        try:\n",
    "            return f\"Result: {eval(expression)}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "    \n",
    "    @tool\n",
    "    def search_cv(query: str) -> str:\n",
    "        \"\"\"Search CV/Resume for education, skills, work experience.\"\"\"\n",
    "        if \"cv_resume\" not in vectorstores:\n",
    "            return \"CV not available.\"\n",
    "        docs = vectorstores[\"cv_resume\"].similarity_search(query, k=3)\n",
    "        return \"\\n\\n\".join([f\"[CV] {d.page_content}\" for d in docs])\n",
    "    \n",
    "    @tool\n",
    "    def search_dms(query: str) -> str:\n",
    "        \"\"\"Search DMS (Deep Mutational Scanning) research documents.\"\"\"\n",
    "        if \"dms_info\" not in vectorstores:\n",
    "            return \"DMS docs not available.\"\n",
    "        docs = vectorstores[\"dms_info\"].similarity_search(query, k=3)\n",
    "        return \"\\n\\n\".join([f\"[DMS] {d.page_content}\" for d in docs])\n",
    "    \n",
    "    @tool\n",
    "    def search_llm_interview(query: str) -> str:\n",
    "        \"\"\"Search LLM/AI/ML interview preparation documents.\"\"\"\n",
    "        if \"llm_interview\" not in vectorstores:\n",
    "            return \"LLM Interview docs not available.\"\n",
    "        docs = vectorstores[\"llm_interview\"].similarity_search(query, k=3)\n",
    "        return \"\\n\\n\".join([f\"[LLM] {d.page_content}\" for d in docs])\n",
    "    \n",
    "    @tool\n",
    "    def search_all(query: str) -> str:\n",
    "        \"\"\"Search ALL documents at once.\"\"\"\n",
    "        results = []\n",
    "        for name, vs in vectorstores.items():\n",
    "            docs = vs.similarity_search(query, k=2)\n",
    "            for d in docs:\n",
    "                results.append(f\"[{name}] {d.page_content[:300]}\")\n",
    "        return \"\\n\\n---\\n\\n\".join(results) if results else \"No results.\"\n",
    "    \n",
    "    tools = [calculator, search_cv, search_dms, search_llm_interview, search_all]\n",
    "\n",
    "    system = \"\"\"You are an intelligent assistant with multiple tools.\n",
    "\n",
    "    TOOLS:\n",
    "    - calculator: Math calculations\n",
    "    - search_cv: Search CV (education, skills, experience)\n",
    "    - search_dms: Search DMS research\n",
    "    - search_llm_interview: Search LLM interview prep\n",
    "    - search_all: Search ALL documents\n",
    "    \n",
    "    STRATEGY:\n",
    "    1. Analyze what information is needed\n",
    "    2. Use appropriate tool(s) - you CAN use multiple\n",
    "    3. Synthesize comprehensive answer\n",
    "    4. Cite sources used\n",
    "\n",
    "    Think step by step.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "    ])\n",
    "    \n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    return AgentExecutor(\n",
    "        agent=agent, tools=tools, verbose=True,\n",
    "        return_intermediate_steps=True, max_iterations=10\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07a38f16-e121-4b07-a931-95f0a667e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag(question, vectorstores):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\" QUESTION: {question}\")\n",
    "    print(f\"{'='*80}\")\n",
    " \n",
    "    \n",
    "    agent = create_agent(vectorstores)\n",
    "    result = agent.invoke({\"input\": question})\n",
    "    \n",
    "    # Extract tools used\n",
    "    tools_used = []\n",
    "    for step in result.get(\"intermediate_steps\", []):\n",
    "        action, _ = step\n",
    "        tools_used.append(action.tool)\n",
    "    \n",
    "    print(f\"\\n TOOLS USED: {tools_used}\")\n",
    "    print(f\"\\n ANSWER:\\n{'-'*80}\\n{result['output']}\\n{'-'*80}\\n\")\n",
    "    \n",
    "    return {\"answer\": result[\"output\"], \"tools_used\": tools_used}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbdef66-9c41-42c0-9f17-0e5eba30139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstores = setup_vectorstores()\n",
    "    \n",
    "test_questions = [\n",
    "        \"Where did Otabek study?\",\n",
    "        \"What is the derivative of ReLU function?\",\n",
    "        \"Compare Otabek's skills with LLM interview topics\",\n",
    "        \"Calculate 5% of 10000 and tell me about DMS project\",\n",
    "        \"Based on all documents, what should I study?\",\n",
    "    ]\n",
    "    \n",
    "for q in test_questions:\n",
    "    query_rag(q, vectorstores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b3ff26-5b38-43d5-9da5-273106d0f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AGENTIC ROUTER CLASS (Alternative Implementation)\n",
    "# =============================================================================\n",
    "class AgenticRouter:\n",
    "    \"\"\"\n",
    "    Agentic Router with dynamic source selection.\n",
    "    Analyzes query complexity and selects appropriate sources.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vectorstores: Dict):\n",
    "        self.vectorstores = vectorstores\n",
    "        self.source_descriptions = SOURCE_DESCRIPTIONS\n",
    "    \n",
    "    def route_and_retrieve(self, query: str):\n",
    "        \"\"\"Agent analyzes query and decides which sources to use.\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\" AGENTIC ROUTING\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Query: {query}\\n\")\n",
    "        \n",
    "        # Step 1: Analyze query complexity\n",
    "        complexity_template = \"\"\"Analyze this query:\n",
    "\n",
    "    Query: {query}\n",
    "    \n",
    "    Is this a:\n",
    "    1. SIMPLE query (needs one source)\n",
    "    2. COMPLEX query (needs multiple sources)\n",
    "    \n",
    "    Type (SIMPLE/COMPLEX):\"\"\"\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_template(complexity_template)\n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        \n",
    "        complexity = chain.invoke({\"query\": query}).strip().upper()\n",
    "        print(f\" Query complexity: {complexity}\")\n",
    "        \n",
    "        # Step 2: Select sources based on complexity\n",
    "        source_list = \"\\n\".join([\n",
    "            f\"- {name}: {desc}\"\n",
    "            for name, desc in self.source_descriptions.items()\n",
    "        ])\n",
    "        \n",
    "        if \"SIMPLE\" in complexity:\n",
    "            # Single source selection\n",
    "            select_template = \"\"\"Select ONE best source:\n",
    "    \n",
    "    Sources:\n",
    "    {sources}\n",
    "    \n",
    "    Query: {query}\n",
    "    \n",
    "    Best source (just the name):\"\"\"\n",
    "\n",
    "            prompt = ChatPromptTemplate.from_template(select_template)\n",
    "            chain = prompt | llm | StrOutputParser()\n",
    "            \n",
    "            selected = chain.invoke({\n",
    "                \"sources\": source_list,\n",
    "                \"query\": query\n",
    "            }).strip().lower()\n",
    "            \n",
    "            sources_to_use = []\n",
    "            for name in self.vectorstores.keys():\n",
    "                if name in selected:\n",
    "                    sources_to_use.append(name)\n",
    "                    break\n",
    "            \n",
    "            if not sources_to_use:\n",
    "                sources_to_use = [list(self.vectorstores.keys())[0]]\n",
    "        \n",
    "        else:  # COMPLEX - multiple sources\n",
    "            select_template = \"\"\"Select ALL relevant sources:\n",
    "\n",
    "    Sources:\n",
    "    {sources}\n",
    "    \n",
    "    Query: {query}\n",
    "    \n",
    "    List sources (comma-separated):\"\"\"\n",
    "\n",
    "            prompt = ChatPromptTemplate.from_template(select_template)\n",
    "            chain = prompt | llm | StrOutputParser()\n",
    "            \n",
    "            selected = chain.invoke({\n",
    "                \"sources\": source_list,\n",
    "                \"query\": query\n",
    "            }).strip().lower()\n",
    "            \n",
    "            sources_to_use = []\n",
    "            for name in self.vectorstores.keys():\n",
    "                if name in selected:\n",
    "                    sources_to_use.append(name)\n",
    "            \n",
    "            if not sources_to_use:\n",
    "                sources_to_use = list(self.vectorstores.keys())\n",
    "        \n",
    "        print(f\" Sources selected: {sources_to_use}\")\n",
    "        \n",
    "        # Step 3: Query selected sources\n",
    "        all_context = []\n",
    "        for source in sources_to_use:\n",
    "            if source in self.vectorstores:\n",
    "                docs = self.vectorstores[source].similarity_search(query, k=3)\n",
    "                if docs:\n",
    "                    all_context.append(f\"[{source.upper()}]\\n\" + format_docs(docs))\n",
    "                    print(f\"   ✓ {source}: {len(docs)} documents\")\n",
    "        \n",
    "        # Step 4: Generate answer\n",
    "        if not all_context:\n",
    "            return sources_to_use, \"No relevant information found.\"\n",
    "        \n",
    "        answer_template = \"\"\"Answer based on the following sources:\n",
    "    \n",
    "    {context}\n",
    "    \n",
    "    Query: {query}\n",
    "    \n",
    "    Answer:\"\"\"\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_template(answer_template)\n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        \n",
    "        answer = chain.invoke({\n",
    "            \"context\": \"\\n\\n\".join(all_context),\n",
    "            \"query\": query\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\" ANSWER:\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(answer)\n",
    "        \n",
    "        return sources_to_use, answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
