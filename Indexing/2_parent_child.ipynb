{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Parent-Child Retriever\n",
    "\n",
    "**What:** Index small chunks for precise search, return large parent chunks for context\n",
    "\n",
    "**Why:** Solves the chunk size dilemma - small=good retrieval, large=good generation\n",
    "\n",
    "**When:** Need balance between precise matching and complete context\n",
    "\n",
    "**The Dilemma:**\n",
    "\n",
    "| Chunk Size | Retrieval | Generation |\n",
    "|------------|-----------|------------|\n",
    "| Small (200) | Precise | Missing context |\n",
    "| Large (2000) | Noisy | Good context |\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Parent (2000 chars) --> stored in docstore with UUID\n",
    "    |\n",
    "    +-- Child 1 (400 chars) --> embedded in vectorstore\n",
    "    +-- Child 2 (400 chars) --> embedded in vectorstore\n",
    "    +-- Child 3 (400 chars) --> embedded in vectorstore\n",
    "\n",
    "Query matches Child 2 --> Returns full Parent\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from config import embeddings, model, load_documents, format_docs\n",
    "\n",
    "# Configuration\n",
    "PARENT_CHUNK_SIZE = 2000\n",
    "PARENT_CHUNK_OVERLAP = 400\n",
    "CHILD_CHUNK_SIZE = 400\n",
    "CHILD_CHUNK_OVERLAP = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Parent-Child Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_child_index(documents):\n",
    "    \"\"\"Create parent-child index manually\"\"\"\n",
    "    print(f\"Processing {len(documents)} documents...\")\n",
    "    \n",
    "    parent_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=PARENT_CHUNK_SIZE, \n",
    "        chunk_overlap=PARENT_CHUNK_OVERLAP\n",
    "    )\n",
    "    child_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHILD_CHUNK_SIZE, \n",
    "        chunk_overlap=CHILD_CHUNK_OVERLAP\n",
    "    )\n",
    "    \n",
    "    parent_store = {}\n",
    "    all_children = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Create parent chunks\n",
    "        parents = parent_splitter.split_documents([doc])\n",
    "        \n",
    "        for parent in parents:\n",
    "            parent_id = str(uuid.uuid4())\n",
    "            parent_store[parent_id] = parent\n",
    "            \n",
    "            # Create child chunks from parent\n",
    "            children = child_splitter.split_documents([parent])\n",
    "            \n",
    "            for child in children:\n",
    "                child.metadata[\"parent_id\"] = parent_id\n",
    "                child.metadata[\"chunk_type\"] = \"child\"\n",
    "            \n",
    "            all_children.extend(children)\n",
    "    \n",
    "    print(f\"Parents: {len(parent_store)}, Children: {len(all_children)}\")\n",
    "    print(f\"Avg children per parent: {len(all_children) / max(len(parent_store), 1):.1f}\")\n",
    "    \n",
    "    # Create vectorstore with children only\n",
    "    vectorstore = FAISS.from_documents(all_children, embeddings)\n",
    "    \n",
    "    return vectorstore, parent_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve with Parent Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_parent(question, vectorstore, parent_store, k=3):\n",
    "    \"\"\"Search children, return parents\"\"\"\n",
    "    print(f\"Question: {question}\\n\")\n",
    "    \n",
    "    # Search child chunks\n",
    "    child_results = vectorstore.similarity_search(question, k=k*2)\n",
    "    print(f\"Found {len(child_results)} matching children\")\n",
    "    \n",
    "    # Get unique parent documents\n",
    "    parent_docs = []\n",
    "    seen_ids = set()\n",
    "    \n",
    "    for child in child_results:\n",
    "        parent_id = child.metadata.get(\"parent_id\")\n",
    "        \n",
    "        if parent_id and parent_id not in seen_ids:\n",
    "            parent = parent_store.get(parent_id)\n",
    "            if parent:\n",
    "                parent_docs.append(parent)\n",
    "                seen_ids.add(parent_id)\n",
    "        \n",
    "        if len(parent_docs) >= k:\n",
    "            break\n",
    "    \n",
    "    print(f\"Retrieved {len(parent_docs)} parent documents\")\n",
    "    return parent_docs, child_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Parent-Child RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent_child_rag(question, vectorstore, parent_store, k=3):\n",
    "    \"\"\"Complete RAG with parent-child retrieval\"\"\"\n",
    "    parent_docs, child_results = retrieve_with_parent(question, vectorstore, parent_store, k)\n",
    "    \n",
    "    context = format_docs(parent_docs)\n",
    "    \n",
    "    template = \"\"\"Answer based on context:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "    \n",
    "    answer = chain.invoke({\"context\": context, \"question\": question})\n",
    "    \n",
    "    print(f\"\\nAnswer: {answer}\")\n",
    "    return answer, parent_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents\n",
    "documents = load_documents()\n",
    "\n",
    "# Create index\n",
    "vectorstore, parent_store = create_parent_child_index(documents)\n",
    "\n",
    "# Test queries\n",
    "test_questions = [\n",
    "    \"What optimization techniques were used?\",\n",
    "    \"What is RF and RDKit?\"\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    print(\"=\"*60)\n",
    "    answer, docs = parent_child_rag(q, vectorstore, parent_store)\n",
    "    print(f\"\\nSources: {len(docs)} parent documents\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"  {i+1}. {doc.metadata.get('filename', 'unknown')} ({len(doc.page_content)} chars)\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
