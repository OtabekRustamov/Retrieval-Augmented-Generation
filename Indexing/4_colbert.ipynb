{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ColBERT (Token-Level Embeddings)\n",
    "\n",
    "**What:** Creates separate embeddings for each token, not a single vector per chunk\n",
    "\n",
    "**Why:** Standard embeddings average all token meanings - small but important terms get lost\n",
    "\n",
    "**When:** Keyword/numeric queries, scientific terminology, exact matches matter\n",
    "\n",
    "**The Problem:**\n",
    "```\n",
    "Document: \"The learning rate was set to 0.001 with Adam optimizer\"\n",
    "Standard: [single 1536-dim vector] --> \"0.001\" gets averaged away\n",
    "Query:    \"What was the learning rate?\" --> May fail to match\n",
    "```\n",
    "\n",
    "**ColBERT Solution:**\n",
    "```\n",
    "Standard Embedding:\n",
    "  \"The learning rate was 0.001\" --> [single 1536-dim vector]\n",
    "  Good for: Conceptual/semantic queries\n",
    "  Bad for:  Specific keywords, exact values\n",
    "\n",
    "ColBERT:\n",
    "  \"The learning rate was 0.001\"\n",
    "    |      |       |    |    |\n",
    "  [v1]   [v2]    [v3] [v4] [v5]  <-- Token-level vectors\n",
    "  Good for: Keyword queries, exact matching\n",
    "  Slower:   More vectors to store and compare\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from config import embeddings, load_documents, format_docs\n",
    "\n",
    "# Check if RAGatouille is available\n",
    "try:\n",
    "    from ragatouille import RAGPretrainedModel\n",
    "    COLBERT_AVAILABLE = True\n",
    "    print(\"ColBERT available via RAGatouille\")\n",
    "except ImportError:\n",
    "    COLBERT_AVAILABLE = False\n",
    "    print(\"RAGatouille not installed. Install with: pip install ragatouille\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ColBERT Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_colbert_index(documents, index_name=\"colbert_index\"):\n",
    "    \"\"\"Create ColBERT token-level index\"\"\"\n",
    "    if not COLBERT_AVAILABLE:\n",
    "        print(\"ColBERT not available\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Creating ColBERT index for {len(documents)} documents...\")\n",
    "    \n",
    "    # Initialize ColBERT\n",
    "    RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "    \n",
    "    # Prepare texts\n",
    "    texts = [doc.page_content for doc in documents]\n",
    "    ids = [f\"doc_{i}\" for i in range(len(documents))]\n",
    "    \n",
    "    # Create index\n",
    "    RAG.index(\n",
    "        collection=texts,\n",
    "        document_ids=ids,\n",
    "        index_name=index_name,\n",
    "        max_document_length=512,\n",
    "        split_documents=True\n",
    "    )\n",
    "    \n",
    "    print(\"ColBERT index created\")\n",
    "    return RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColBERT Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colbert_search(query, RAG, k=3):\n",
    "    \"\"\"Search using ColBERT token-level matching\"\"\"\n",
    "    if RAG is None:\n",
    "        print(\"No ColBERT index available\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    \n",
    "    results = RAG.search(query, k=k)\n",
    "    \n",
    "    print(f\"Found {len(results)} results:\")\n",
    "    for i, r in enumerate(results):\n",
    "        score = r.get('score', 0)\n",
    "        content = r.get('content', '')[:80]\n",
    "        print(f\"  {i+1}. (score: {score:.3f}) {content}...\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Standard vs ColBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_standard_vs_colbert(query, documents, RAG, k=3):\n",
    "    \"\"\"Compare standard embedding search vs ColBERT\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"COMPARISON: Standard vs ColBERT\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"(ColBERT excels at keyword/exact-value queries)\\n\")\n",
    "    \n",
    "    # Standard embedding search\n",
    "    print(\"--- STANDARD EMBEDDING ---\")\n",
    "    vectorstore = FAISS.from_documents(documents[:30], embeddings)\n",
    "    standard_results = vectorstore.similarity_search(query, k=k)\n",
    "    \n",
    "    for i, doc in enumerate(standard_results):\n",
    "        print(f\"  {i+1}. {doc.page_content[:80]}...\")\n",
    "    \n",
    "    # ColBERT search\n",
    "    if RAG:\n",
    "        print(\"\\n--- COLBERT ---\")\n",
    "        colbert_results = RAG.search(query, k=k)\n",
    "        \n",
    "        for i, r in enumerate(colbert_results):\n",
    "            score = r.get('score', 0)\n",
    "            content = r.get('content', '')[:80]\n",
    "            print(f\"  {i+1}. (score: {score:.3f}) {content}...\")\n",
    "    \n",
    "    return standard_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents\n",
    "documents = load_documents()\n",
    "\n",
    "if not COLBERT_AVAILABLE:\n",
    "    print(\"Install RAGatouille to test ColBERT: pip install ragatouille\")\n",
    "else:\n",
    "    # Create index\n",
    "    RAG = create_colbert_index(documents[:20], index_name=\"test_colbert\")\n",
    "    \n",
    "    # Test keyword queries (ColBERT excels here)\n",
    "    keyword_queries = [\n",
    "        \"learning rate 0.001\",\n",
    "        \"Adam optimizer\",\n",
    "        \"molecular weight threshold\"\n",
    "    ]\n",
    "    \n",
    "    for query in keyword_queries:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        colbert_search(query, RAG, k=3)\n",
    "    \n",
    "    # Compare with standard\n",
    "    print(\"\\n\")\n",
    "    compare_standard_vs_colbert(\"Adam optimizer learning rate\", documents[:20], RAG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
