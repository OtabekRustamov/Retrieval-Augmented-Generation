{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Document Summary Indexing\n",
    "\n",
    "**What:** Generate a summary for each document and index those summaries\n",
    "\n",
    "**Why:** Summaries capture core meaning, enabling fast document discovery\n",
    "\n",
    "**When:** Large documents, document-level retrieval rather than chunk-level\n",
    "\n",
    "**How It Relates to Multi-Representation:**\n",
    "- Multi-Rep: Complex, UUID linking, always returns full document\n",
    "- Doc Summary: Simpler, can return just summary or full document\n",
    "\n",
    "**Use Cases:**\n",
    "1. Document Discovery - quickly identify relevant documents\n",
    "2. Summary-First RAG - retrieve summaries first, then fetch details\n",
    "3. Hybrid Retrieval - search both summaries and chunks\n",
    "\n",
    "**Variations:**\n",
    "1. Summary Only - retrieve summaries\n",
    "2. Summary + Full Document - store original, return on match\n",
    "3. Summary + Chunks - index both for broad and fine-grained retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from config import model, embeddings, load_documents, format_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Summary Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_index(documents, max_docs=None):\n",
    "    \"\"\"Create vectorstore with document summaries\"\"\"\n",
    "    if max_docs:\n",
    "        documents = documents[:max_docs]\n",
    "    \n",
    "    print(f\"Creating summary index for {len(documents)} documents...\")\n",
    "    \n",
    "    template = \"\"\"Summarize in 2-3 sentences:\n",
    "\n",
    "{document}\n",
    "\n",
    "Summary:\"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "    \n",
    "    summary_docs = []\n",
    "    \n",
    "    for i, doc in enumerate(documents):\n",
    "        print(f\"  [{i+1}/{len(documents)}] Summarizing...\")\n",
    "        \n",
    "        # Generate summary\n",
    "        summary = chain.invoke({\"document\": doc.page_content[:4000]})\n",
    "        \n",
    "        # Create summary document with original stored in metadata\n",
    "        summary_doc = Document(\n",
    "            page_content=summary,\n",
    "            metadata={\n",
    "                \"original_content\": doc.page_content,\n",
    "                \"summary\": summary,\n",
    "                \"doc_index\": i,\n",
    "                \"source\": doc.metadata.get(\"filename\", \"unknown\")\n",
    "            }\n",
    "        )\n",
    "        summary_docs.append(summary_doc)\n",
    "    \n",
    "    # Create vectorstore from summaries\n",
    "    vectorstore = FAISS.from_documents(summary_docs, embeddings)\n",
    "    \n",
    "    print(f\"Created index with {len(summary_docs)} summaries\")\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve with Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_summaries(query, vectorstore, k=3, return_original=True):\n",
    "    \"\"\"Search summaries, optionally return original documents\"\"\"\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    \n",
    "    # Search summaries\n",
    "    summaries = vectorstore.similarity_search(query, k=k)\n",
    "    \n",
    "    print(f\"Matched {len(summaries)} summaries:\")\n",
    "    for i, s in enumerate(summaries):\n",
    "        print(f\"  {i+1}. {s.page_content[:80]}...\")\n",
    "    \n",
    "    if return_original:\n",
    "        # Return original documents from metadata\n",
    "        results = []\n",
    "        for summary in summaries:\n",
    "            original = summary.metadata.get(\"original_content\", \"\")\n",
    "            if original:\n",
    "                results.append(Document(\n",
    "                    page_content=original,\n",
    "                    metadata={\n",
    "                        \"summary\": summary.page_content,\n",
    "                        \"source\": summary.metadata.get(\"source\")\n",
    "                    }\n",
    "                ))\n",
    "            else:\n",
    "                results.append(summary)\n",
    "        return results\n",
    "    \n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Document Summary RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_indexing_rag(question, vectorstore, k=3):\n",
    "    \"\"\"Complete RAG with document summary indexing\"\"\"\n",
    "    docs = retrieve_with_summaries(question, vectorstore, k, return_original=True)\n",
    "    \n",
    "    context = format_docs(docs)\n",
    "    \n",
    "    template = \"\"\"Answer based on context:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "    \n",
    "    answer = chain.invoke({\"context\": context, \"question\": question})\n",
    "    \n",
    "    print(f\"\\nAnswer: {answer}\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents\n",
    "documents = load_documents()\n",
    "\n",
    "# Create summary index (limit for speed)\n",
    "vectorstore = create_summary_index(documents, max_docs=5)\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"What is the main topic?\",\n",
    "    \"What research was conducted?\",\n",
    "    \"What are the key findings?\"\n",
    "]\n",
    "\n",
    "for q in test_queries:\n",
    "    print(\"=\"*60)\n",
    "    summary_indexing_rag(q, vectorstore, k=2)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
